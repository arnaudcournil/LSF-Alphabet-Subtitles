{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "c:\\Users\\courn\\Desktop\\Projet ML\\LSF-Alphabet-Subtitles\\.venv\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.NONE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from unidecode import unidecode\n",
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"dictionnaire.txt\", 'r', encoding='latin1') as file1:\n",
    "    with open(\"lexiqueorgdico.txt\", 'r', encoding='latin1') as file2:\n",
    "        file = list(set(file1).union(set(file2)))\n",
    "        french_words = [unidecode(word.lower().strip()) for word in file if all(c in \"abcdefghijklmnopqrstuvwxyzéèàçù\" for c in word.strip().lower())]\n",
    "\n",
    "def capitalize_sentences(text):\n",
    "    # Utilisation de re.sub pour identifier chaque phrase et mettre la première lettre en majuscule\n",
    "    return re.sub(r'(^|(?<=[.!?…])\\s+)([a-z])', lambda match: match.group(1) + match.group(2).upper(), text)\n",
    "\n",
    "model = PunctuationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['j', 'aime', 'let'], 'empslactionlamertume')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maxMatch(string):\n",
    "    tokens = []\n",
    "    not_in = \"\"\n",
    "    i = 0\n",
    "    while i < len(string):\n",
    "        maxWord = \"\"\n",
    "        for j in range(i, len(string)):\n",
    "            tempWord = string[i:j+1]\n",
    "            if tempWord in french_words and len(tempWord) > len(maxWord):\n",
    "                maxWord = tempWord\n",
    "        if len(maxWord) == 0:\n",
    "            not_in = string[i:j+1]\n",
    "            break\n",
    "        i = i+len(maxWord)\n",
    "        tokens.append(maxWord)\n",
    "    return tokens, not_in\n",
    "\n",
    "string = \"jaimeletempslactionlamertume\"\n",
    "maxMatch(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['j',\n",
       "  'aime',\n",
       "  'let',\n",
       "  'e',\n",
       "  'm',\n",
       "  'p',\n",
       "  's',\n",
       "  'lac',\n",
       "  't',\n",
       "  'ion',\n",
       "  'lamer',\n",
       "  'tu',\n",
       "  'me'],\n",
       " [0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def completeMaxMatch(string):\n",
    "    tokens, not_in = maxMatch(string)\n",
    "    not_in_array = [0] * len(tokens)\n",
    "    while len(not_in) > 0:\n",
    "        tokens.append(not_in[0])\n",
    "        not_in_array.append(1)\n",
    "        not_in  = not_in[1:]\n",
    "        if len(not_in) > 0:\n",
    "            tokens_, not_in = maxMatch(not_in)\n",
    "            tokens.extend(tokens_)\n",
    "            not_in_array.extend([0] * len(tokens_))\n",
    "    return  tokens, not_in_array\n",
    "\n",
    "string = \"jaimeletempslactionlamertume\"\n",
    "completeMaxMatch(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['amertume'], 'jaimeletempslactionl')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reverseMaxMatch(string):\n",
    "    tokens = []\n",
    "    not_in = \"\"\n",
    "    i = len(string)\n",
    "    while i > 0:\n",
    "        maxWord = \"\"\n",
    "        for j in range(i - 1, -1, -1):\n",
    "            tempWord = string[j:i]\n",
    "            if tempWord in french_words and len(tempWord) > len(maxWord):\n",
    "                maxWord = tempWord\n",
    "        if len(maxWord) == 0:\n",
    "            not_in = string[j:i]\n",
    "            break\n",
    "        i = i - len(maxWord)\n",
    "        tokens.append(maxWord)\n",
    "    return tokens[::-1], not_in\n",
    "\n",
    "string = \"jaimeletempslactionlamertume\"\n",
    "reverseMaxMatch(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['j', 'aime', 'le', 'temps', 'l', 'action', 'l', 'amertume'],\n",
       " [0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def completeReverseMaxMatch(string):\n",
    "    tokens, not_in = reverseMaxMatch(string)\n",
    "    not_in_array = [0] * len(tokens)\n",
    "    while len(not_in) > 0:\n",
    "        tokens.insert(0, not_in[-1])\n",
    "        not_in_array.insert(0, 1)\n",
    "        not_in  = not_in[:-1]\n",
    "        if len(not_in) > 0:\n",
    "            tokens_, not_in = reverseMaxMatch(not_in)\n",
    "            tokens = tokens_ + tokens \n",
    "            not_in_array = [0] * len(tokens_) + not_in_array\n",
    "    return tokens, not_in_array\n",
    "\n",
    "string = \"jaimeletempslactionlamertume\"\n",
    "completeReverseMaxMatch(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits_idx(all_tokens_l):\n",
    "    l_splits_idx = []\n",
    "    sum_ = 0\n",
    "    for token in all_tokens_l:\n",
    "        sum_ += len(token)\n",
    "        l_splits_idx.append(sum_)\n",
    "    return l_splits_idx\n",
    "\n",
    "def compare_tokens_list(all_tokens_l1, not_in_array_l1, all_tokens_l2, not_in_array_l2):\n",
    "    if sum(not_in_array_l1) <  sum(not_in_array_l2):\n",
    "        return all_tokens_l1\n",
    "    elif sum(not_in_array_l1) > sum(not_in_array_l2):\n",
    "        return all_tokens_l2\n",
    "    else:\n",
    "        sum_square_len_l1 = sum([len(word) ** 2 for word in all_tokens_l1])\n",
    "        sum_square_len_l2 = sum([len(word) ** 2 for word in all_tokens_l2])\n",
    "        return all_tokens_l1 if sum_square_len_l1 > sum_square_len_l2 else all_tokens_l2\n",
    "\n",
    "def mix_algo(string):\n",
    "    tokens_max, not_in_array_max = completeMaxMatch(string)\n",
    "    tokens_reverse_max, not_in_array_reverse_max = completeReverseMaxMatch(string)\n",
    "\n",
    "    max_splits_idx = get_splits_idx(tokens_max)\n",
    "    reverse_max_splits_idx = get_splits_idx(tokens_reverse_max)\n",
    "    \n",
    "    finals_words = []\n",
    "    i_act = 0\n",
    "    j_act = 0\n",
    "    for i in range(len(max_splits_idx)):\n",
    "        for j in range(j_act, len(reverse_max_splits_idx)):\n",
    "            if max_splits_idx[i] == reverse_max_splits_idx[j]:\n",
    "                finals_words.extend(compare_tokens_list(tokens_max[i_act : i + 1], not_in_array_max[i_act : i + 1], tokens_reverse_max[j_act : j + 1], not_in_array_reverse_max[j_act : j + 1]))\n",
    "                i_act = i + 1\n",
    "                j_act = j + 1\n",
    "                break\n",
    "    return finals_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_optimise(string):\n",
    "    MAX_WORD_LENGTH = 25\n",
    "    confirmed_ = []\n",
    "    next_ = []\n",
    "    next_raw  = []\n",
    "    i = 0\n",
    "    while True :\n",
    "        next_ = mix_algo(string[i:i+MAX_WORD_LENGTH])\n",
    "        if i + MAX_WORD_LENGTH >= len(string):\n",
    "            next_raw = string[i:i+MAX_WORD_LENGTH]\n",
    "            break\n",
    "        else:\n",
    "            confirmed_.append(next_[0])\n",
    "            i += len(next_[0])\n",
    "        \n",
    "    return confirmed_, next_, next_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3642868995666504\n",
      "0.08113861083984375\n",
      "0.09110474586486816\n",
      "0.09232091903686523\n",
      "0.10866689682006836\n",
      "0.10566186904907227\n",
      "0.12026357650756836\n",
      "0.1308591365814209\n",
      "0.13041353225708008\n",
      "0.16025900840759277\n",
      "0.17586255073547363\n",
      "0.18616628646850586\n",
      "0.18634653091430664\n",
      "0.19272351264953613\n",
      "0.22929668426513672\n",
      "0.24340486526489258\n",
      "0.27930283546447754\n",
      "0.25632190704345703\n",
      "0.2666773796081543\n",
      "0.33224964141845703\n",
      "0.3291130065917969\n",
      "0.3187687397003174\n",
      "0.3187122344970703\n",
      "0.3712291717529297\n",
      "0.43076109886169434\n",
      "0.39023470878601074\n",
      "0.5013022422790527\n",
      "0.6316475868225098\n",
      "0.576901912689209\n",
      "0.503044843673706\n",
      "0.49495625495910645\n",
      "0.5639760494232178\n",
      "0.646714448928833\n",
      "0.7658421993255615\n",
      "0.7108008861541748\n",
      "0.7101924419403076\n",
      "0.756040096282959\n",
      "0.6435153484344482\n",
      "0.6588184833526611\n",
      "0.7362382411956787\n",
      "0.8151490688323975\n",
      "0.7497823238372803\n",
      "0.851689338684082\n",
      "0.8791098594665527\n",
      "0.8757216930389404\n",
      "0.8282585144042969\n",
      "0.8694193363189697\n",
      "0.8721764087677002\n",
      "0.9860200881958008\n",
      "1.2975318431854248\n",
      "1.1001019477844238\n",
      "1.0887763500213623\n",
      "1.036961555480957\n",
      "1.084876537322998\n",
      "1.274656057357788\n",
      "1.3392670154571533\n",
      "1.3590874671936035\n",
      "1.3522114753723145\n",
      "1.5137758255004883\n",
      "1.591783046722412\n",
      "1.7283611297607422\n",
      "1.5754895210266113\n",
      "1.825484037399292\n",
      "1.9255154132843018\n",
      "1.8087489604949951\n",
      "1.8680992126464844\n",
      "2.018789529800415\n",
      "2.0666182041168213\n",
      "2.234710693359375\n",
      "1.9326958656311035\n",
      "1.8382723331451416\n",
      "1.884394645690918\n",
      "1.968109130859375\n",
      "2.0565359592437744\n",
      "1.9793798923492432\n",
      "1.9350101947784424\n",
      "2.0781517028808594\n",
      "2.321221113204956\n",
      "2.258362054824829\n",
      "2.244370222091675\n",
      "2.2453794479370117\n",
      "2.4893665313720703\n",
      "2.836336374282837\n",
      "Le ciel est bleu. J aides amis qui sont aussi mes amoureux et des chemins qui sont aussi un peul es miens.\n"
     ]
    }
   ],
   "source": [
    "all_keys = \"lecielestbleujaidesamisquisontaussimesamoureuxetdescheminsquisontaussiunpeulesmiens\"\n",
    "next_raw = \"\"\n",
    "confirmed  = []\n",
    "\n",
    "for key in all_keys:\n",
    "    next_raw += key # Ajout d'une lettre\n",
    "    start = time.time()\n",
    "    confirmed = mix_algo(next_raw)\n",
    "    result = re.sub(r\"\\b([JjLlCc]) (\\w+)\", r\"\\1'\\2\", capitalize_sentences(model.restore_punctuation(\" \".join(confirmed))))\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10761380195617676\n",
      "0.09238553047180176\n",
      "0.10279297828674316\n",
      "0.09963607788085938\n",
      "0.12524747848510742\n",
      "0.12404990196228027\n",
      "0.13698601722717285\n",
      "0.13226938247680664\n",
      "0.12989425659179688\n",
      "0.15300726890563965\n",
      "0.1855030059814453\n",
      "0.21556448936462402\n",
      "0.2089405059814453\n",
      "0.23837542533874512\n",
      "0.2292780876159668\n",
      "0.2295215129852295\n",
      "0.26164746284484863\n",
      "0.24991965293884277\n",
      "0.27812981605529785\n",
      "0.3737657070159912\n",
      "0.479999303817749\n",
      "0.43828463554382324\n",
      "0.4238002300262451\n",
      "0.4588890075683594\n",
      "0.40859556198120117\n",
      "0.677424430847168\n",
      "0.3771078586578369\n",
      "0.6629929542541504\n",
      "0.36408019065856934\n",
      "0.33022522926330566\n",
      "0.41300034523010254\n",
      "0.6243979930877686\n",
      "0.40465760231018066\n",
      "0.4186713695526123\n",
      "0.7170510292053223\n",
      "0.39542722702026367\n",
      "0.34298133850097656\n",
      "0.39655590057373047\n",
      "0.534895658493042\n",
      "0.43728184700012207\n",
      "0.2968776226043701\n",
      "0.39327406883239746\n",
      "0.35272717475891113\n",
      "0.3894221782684326\n",
      "0.5351588726043701\n",
      "0.35786938667297363\n",
      "0.3358163833618164\n",
      "0.3562591075897217\n",
      "0.5050718784332275\n",
      "0.3605508804321289\n",
      "0.43928027153015137\n",
      "0.49681758880615234\n",
      "0.30141186714172363\n",
      "0.33127307891845703\n",
      "0.3787555694580078\n",
      "0.6266834735870361\n",
      "0.2878382205963135\n",
      "0.28644394874572754\n",
      "0.32387280464172363\n",
      "0.3677818775177002\n",
      "0.5161178112030029\n",
      "0.30906152725219727\n",
      "0.33427929878234863\n",
      "0.4769308567047119\n",
      "0.23013806343078613\n",
      "0.2695353031158447\n",
      "0.2779233455657959\n",
      "0.3143134117126465\n",
      "0.35080671310424805\n",
      "0.2936382293701172\n",
      "0.3352329730987549\n",
      "0.50282883644104\n",
      "0.32816648483276367\n",
      "0.5315032005310059\n",
      "0.31223177909851074\n",
      "0.3105778694152832\n",
      "0.5122947692871094\n",
      "0.27841830253601074\n",
      "0.31581902503967285\n",
      "0.3252706527709961\n",
      "0.3772578239440918\n",
      "0.3881855010986328\n",
      "0.36133670806884766\n",
      "Le ciel est bleu. J aides amis qui sont aussi mes amoureux et des chemins qui sont aussi un peul es miens.\n"
     ]
    }
   ],
   "source": [
    "all_keys = \"lecielestbleujaidesamisquisontaussimesamoureuxetdescheminsquisontaussiunpeulesmiens\"\n",
    "next_raw = \"\"\n",
    "next_ = []\n",
    "confirmed  = []\n",
    "\n",
    "for key in all_keys:\n",
    "    next_raw += key # Ajout d'une lettre\n",
    "    start = time.time()\n",
    "    confirmed_, next_, next_raw = algo_optimise(next_raw)\n",
    "    result = capitalize_sentences(model.restore_punctuation(\" \".join(confirmed + next_)))\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    confirmed.extend(confirmed_)\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_espace</th>\n",
       "      <th>phrase_concat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quel architecte fut a l origine des plans du w...</td>\n",
       "      <td>quelarchitectefutaloriginedesplansduwoolworthb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ou se trouvait franck woolworth lors de l inau...</td>\n",
       "      <td>ousetrouvaitfranckwoolworthlorsdelinauguration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment fut paye le batiment commande par fran...</td>\n",
       "      <td>commentfutpayelebatimentcommandeparfranckwoolw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en quelle annee ouvrit le woolworth building</td>\n",
       "      <td>enquelleanneeouvritlewoolworthbuilding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qui commanda la construction du woolworth buil...</td>\n",
       "      <td>quicommandalaconstructionduwoolworthbuilding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       phrase_espace  \\\n",
       "0  quel architecte fut a l origine des plans du w...   \n",
       "1  ou se trouvait franck woolworth lors de l inau...   \n",
       "2  comment fut paye le batiment commande par fran...   \n",
       "3       en quelle annee ouvrit le woolworth building   \n",
       "4  qui commanda la construction du woolworth buil...   \n",
       "\n",
       "                                       phrase_concat  \n",
       "0  quelarchitectefutaloriginedesplansduwoolworthb...  \n",
       "1  ousetrouvaitfranckwoolworthlorsdelinauguration...  \n",
       "2  commentfutpayelebatimentcommandeparfranckwoolw...  \n",
       "3             enquelleanneeouvritlewoolworthbuilding  \n",
       "4       quicommandalaconstructionduwoolworthbuilding  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nettoyer_texte(texte):\n",
    "    # Enlever les accents\n",
    "    texte = unidecode(texte)\n",
    "    # Remplacer les apostrophes par un espace\n",
    "    texte = texte.replace(\"'\", \" \")\n",
    "    # Enlever la ponctuation\n",
    "    texte = re.sub(r\"[^\\w\\s]\", \"\", texte)\n",
    "    # Mettre en minuscule\n",
    "    texte = texte.lower()\n",
    "    return texte\n",
    "\n",
    "df = pd.read_csv(\"questoin-reponse.csv\")\n",
    "df[\"phrase_espace\"] =  df[\"question\"].apply(nettoyer_texte).str.strip()\n",
    "df[\"phrase_concat\"] = df[\"phrase_espace\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "del  df[\"question\"]\n",
    "del df[\"reponse\"]\n",
    "\n",
    "df = df[:1000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    real_tokens = row[\"phrase_espace\"].split()\n",
    "    tokens_mix_algo = mix_algo(row[\"phrase_concat\"])\n",
    "    pred_mix_algo = \" \".join(tokens_mix_algo)\n",
    "    df.at[index, \"pred_mix_algo\"] = pred_mix_algo\n",
    "    relative_accuracy_mix_algo = len(set(real_tokens).intersection(set(tokens_mix_algo))) / len(set(real_tokens))\n",
    "    df.at[index, \"relative_accuracy_mix_algo\"] = relative_accuracy_mix_algo\n",
    "    tokens_max_match = completeMaxMatch(row[\"phrase_concat\"])[0]\n",
    "    pred_max_match = \" \".join(tokens_max_match)\n",
    "    df.at[index, \"pred_max_match\"] = pred_max_match\n",
    "    relative_accuracy_max_match = len(set(real_tokens).intersection(set(tokens_max_match))) / len(set(real_tokens))\n",
    "    df.at[index, \"relative_accuracy_max_match\"] = relative_accuracy_max_match\n",
    "    tokens_reverse_max_match = completeReverseMaxMatch(row[\"phrase_concat\"])[0]\n",
    "    pred_reverse_max_match = \" \".join(tokens_reverse_max_match)\n",
    "    df.at[index, \"pred_reverse_max_match\"] = pred_reverse_max_match\n",
    "    relative_accuracy_reverse_max_match = len(set(real_tokens).intersection(set(tokens_reverse_max_match))) / len(set(real_tokens))\n",
    "    df.at[index, \"relative_accuracy_reverse_max_match\"] = relative_accuracy_reverse_max_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algo mixte: \n",
      "4.2 % de précision exacte\n",
      "65.79488167104653 % de mots corrects en moyenne\n",
      "Max match: \n",
      "1.9 % de précision exacte\n",
      "59.57251336254045 % de mots corrects en moyenne\n",
      "Reverse max match: \n",
      "3.5000000000000004 % de précision exacte\n",
      "63.67959902111991 % de mots corrects en moyenne\n"
     ]
    }
   ],
   "source": [
    "mean_algo = sum(df[\"pred_mix_algo\"] == df[\"phrase_espace\"]) / len(df)\n",
    "relative_accuracy_algo = df[\"relative_accuracy_mix_algo\"].mean()\n",
    "mean_max_match = sum(df[\"pred_max_match\"] == df[\"phrase_espace\"]) / len(df)\n",
    "relative_accuracy_max_match = df[\"relative_accuracy_max_match\"].mean()\n",
    "mean_reverse_max_match = sum(df[\"pred_reverse_max_match\"] == df[\"phrase_espace\"]) / len(df)\n",
    "relative_accuracy_reverse_max_match = df[\"relative_accuracy_reverse_max_match\"].mean()\n",
    "print(\"Algo mixte: \")\n",
    "print(mean_algo * 100, \"%\", \"de précision exacte\")\n",
    "print(relative_accuracy_algo * 100, \"%\", \"de mots corrects en moyenne\")\n",
    "print(\"Max match: \")\n",
    "print(mean_max_match * 100, \"%\", \"de précision exacte\")\n",
    "print(relative_accuracy_max_match * 100, \"%\", \"de mots corrects en moyenne\")\n",
    "print(\"Reverse max match: \")\n",
    "print(mean_reverse_max_match * 100, \"%\", \"de précision exacte\")\n",
    "print(relative_accuracy_reverse_max_match * 100, \"%\", \"de mots corrects en moyenne\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
